* getting the RGB images from the two cameras

—- joints —-
(For both camera images)
* filtering the images with the colours of the joints (yellow, blue, green, red)
* making the detected blobs bigger
* calculating the center of mass for every joint to get the pixel coordinates
* combining the pixel coordinates to 3D x,y,z coordinates
* using som formula to get the angles between the joints

—- targets —-
(For both camera images)
* filtering the images with the colours of the targets orange)
* making the detected blobs bigger and smaller 
* calculating the center of mass for every joint to get the pixel coordinates
* finding the boundaries of the target objects 
* cropping the binary images targets
* classifying the targets if it’s a square or a circle with a SVM classifier
* combining the pixel coordinates to 3D x,y,z coordinates
* converting the coordinates of the targets to the base frame coordinate system (to implement)
