{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ObjectDetection import ObjectDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printImgCol(img):\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "def printImgGray(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input_path\n",
    "output_path = os.path.join(os.getcwd(), 'images_training')\n",
    "input_path = os.path.join(os.getcwd(), 'images_ros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/philipp/Code/ivr_robotic_arm/test_svm/images_ros'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = ObjectDetection()\n",
    "\n",
    "for i in range(1,10):\n",
    "    img = cv2.imread(input_path+'/image_1_'+str(i)+'.png',1)\n",
    "    img2 = od.filter_orange(img)\n",
    "    img2 = od.opening(img2, 3)\n",
    "    img2 = od.dilate(img2, 3)\n",
    "    rects, cnts = od.find_boundries(img2)\n",
    "    \n",
    "    print(len(rects))\n",
    "    for j in range(0,len(rects)):\n",
    "        obj = od.get_object(img2, rects[j])\n",
    "        cv2.imwrite(output_path + '/obj'+str(i)+'_'+str(j)+'.jpg', obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = dict(kernel_type=cv2.ml.SVM_LINEAR,\n",
    "                               svm_type=cv2.ml.SVM_C_SVC,\n",
    "                               C=2.67, gamma=5.383)\n",
    "classes = [['obj0', 8], ['obj1', 8]]\n",
    "dim = 3\n",
    "\n",
    "samples = np.array([[]], dtype=np.float32)\n",
    "samples_labels = np.array([], dtype=np.int)\n",
    "svm = cv2.ml.SVM_create()\n",
    "svm.setType(cv2.ml.SVM_C_SVC)\n",
    "svm.setKernel(cv2.ml.SVM_LINEAR)\n",
    "svm.setTermCriteria((cv2.TERM_CRITERIA_COUNT, 100, 1.e-06))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTrainSamples(folder, samples, samples_labels):\n",
    "    #kernel = np.ones((5, 5), np.uint8)\n",
    "    class_key = 0\n",
    "    for c in classes:\n",
    "        for i in range(0, c[1]):\n",
    "            filename = folder + '/' + c[0] + '_' + str(i) + '.jpg'\n",
    "            img = cv2.imread(filename, 0)\n",
    "            ret, img_bin = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "            #img = l25.loadImage(filename, 0)\n",
    "            #thresh = l32.peakPick(img)\n",
    "            #img_bin = abs(l32.threshold(img, thresh) - 1)  # Given this set of data we need to flip the values\n",
    "            #img_bin = cv2.erode(img_bin, kernel, iterations=2)\n",
    "            moment = cv2.moments(img)\n",
    "            img_props = cv2.HuMoments(moment)\n",
    "            img_props = img_props.reshape((1, 7)).astype(np.float32)\n",
    "            #img_props = np.array([l42.getproperties(img_bin)], dtype=np.float32)\n",
    "            if samples.size == 0:\n",
    "                samples = img_props\n",
    "            else:\n",
    "                samples = np.append(samples, img_props, axis=0)\n",
    "            samples_labels = np.append(samples_labels, np.array([class_key], dtype=np.int))\n",
    "        class_key += 1\n",
    "    return samples, samples_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (<ipython-input-7-4100c5b9b71f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-4100c5b9b71f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def train(model=\"\", load=False, svm):\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "def train(model=\"\", load=False, svm):\n",
    "    if load:\n",
    "        try:\n",
    "            svm = self.svm.load(model)\n",
    "        except:\n",
    "            print(\"Provide a valid xml file.\")\n",
    "    else:\n",
    "        self.svm.train(self.samples, cv2.ml.ROW_SAMPLE, self.samples_labels)\n",
    "        if model != \"\":\n",
    "            try:\n",
    "                self.svm.save(model)\n",
    "            except:\n",
    "                print(\"The filename must be valid.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(self, filename):\n",
    "    img = cv2.imread(filename, 0)\n",
    "    #kernel = np.ones((5, 5), np.uint8)\n",
    "    thresh = l32.peakPick(img)\n",
    "    #img_bin = abs(l32.threshold(img, thresh) - 1)  # Given this set of data we need to flip the values\n",
    "    #img_bin = cv2.erode(img_bin, kernel, iterations=2)\n",
    "    ret, img_bin = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "    #img_props = np.array([l42.getproperties(img_bin)], dtype=np.float32)\n",
    "    moment = cv2.moments(img)\n",
    "    img_props = cv2.HuMoments(moment)\n",
    "    img_props = img_props.reshape((1, 7)).astype(np.float32)\n",
    "    prediction = self.svm.predict(img_props)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, samples_labels = addTrainSamples('images_train', samples, samples_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.8032574e-04,  5.1930323e-07,  5.3627740e-18,  1.4389200e-15,\n",
       "        -1.2640078e-31,  1.0369246e-18, -5.5687601e-42],\n",
       "       [ 9.7668730e-04,  5.1132611e-07,  2.4529219e-17,  2.5234401e-15,\n",
       "         6.2781451e-31,  1.8044381e-18, -0.0000000e+00],\n",
       "       [ 8.8992424e-04,  3.5285606e-07,  1.8926987e-15,  3.4241667e-15,\n",
       "         8.7171208e-30,  2.0340127e-18,  3.0694042e-41],\n",
       "       [ 8.5529400e-04,  3.0333280e-07,  5.0342531e-15,  2.9605396e-15,\n",
       "         1.1429411e-29,  1.6305367e-18,  3.7930347e-41],\n",
       "       [ 8.8992424e-04,  3.5285606e-07,  1.8926987e-15,  3.4241667e-15,\n",
       "         8.7171208e-30,  2.0340127e-18,  3.0694042e-41],\n",
       "       [ 9.2438876e-04,  4.1089078e-07,  8.6873042e-17,  8.9230696e-16,\n",
       "         2.4843565e-31,  5.7197554e-19,  7.2026741e-43],\n",
       "       [ 9.2438876e-04,  4.1089078e-07,  8.6873042e-17,  8.9230696e-16,\n",
       "         2.4843565e-31,  5.7197554e-19,  7.2026741e-43],\n",
       "       [ 8.8992424e-04,  3.5285606e-07,  1.8926987e-15,  3.4241667e-15,\n",
       "         8.7171208e-30,  2.0340127e-18,  3.0694042e-41],\n",
       "       [ 6.6691026e-04,  2.3023713e-08,  1.1391155e-11,  5.1498942e-13,\n",
       "        -1.2080700e-24, -7.7140224e-17, -3.1048200e-25],\n",
       "       [ 6.6915032e-04,  2.2516318e-08,  1.7094324e-11,  7.9404213e-13,\n",
       "        -2.8863645e-24, -1.1768538e-16, -4.7655403e-25],\n",
       "       [ 6.7896704e-04,  2.6933467e-08,  1.8945642e-11,  1.0448107e-12,\n",
       "        -4.6462219e-24, -1.7064238e-16,  1.4491652e-25],\n",
       "       [ 6.8012212e-04,  2.6348005e-08,  1.9411832e-11,  1.1585570e-12,\n",
       "        -5.4047523e-24, -1.8707192e-16,  9.8770858e-25],\n",
       "       [ 6.7359838e-04,  2.1960759e-08,  1.6406496e-11,  9.1100413e-13,\n",
       "        -3.5063771e-24, -1.3378856e-16,  3.3128564e-25],\n",
       "       [ 6.7452324e-04,  3.2590318e-08,  1.2330044e-11,  6.8026444e-13,\n",
       "        -1.9695048e-24, -1.2278522e-16,  5.0355355e-26],\n",
       "       [ 6.6880032e-04,  2.4274785e-08,  1.2681613e-11,  6.5315158e-13,\n",
       "        -1.8306718e-24, -1.0161431e-16, -4.2688749e-25],\n",
       "       [ 6.7877921e-04,  2.5679332e-08,  1.9456386e-11,  1.0683427e-12,\n",
       "        -4.8690929e-24, -1.6941416e-16,  1.2751128e-25]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "svm.train(samples, cv2.ml.ROW_SAMPLE, samples_labels)\n",
    "svm.save('classifier_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, array([[1.]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('images_test/test_obj1_0.jpg', 0)\n",
    "#kernel = np.ones((5, 5), np.uint8)\n",
    "#thresh = l32.peakPick(img)\n",
    "#img_bin = abs(l32.threshold(img, thresh) - 1)  # Given this set of data we need to flip the values\n",
    "#img_bin = cv2.erode(img_bin, kernel, iterations=2)\n",
    "ret, img_bin = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "#img_props = np.array([l42.getproperties(img_bin)], dtype=np.float32)\n",
    "moment = cv2.moments(img_bin)\n",
    "img_props = cv2.HuMoments(moment)\n",
    "img_props = img_props.reshape((1, 7)).astype(np.float32)\n",
    "prediction = svm.predict(img_props)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'images_train/obj1_6.jpg'\n",
    "img = cv2.imread(filename, 0)\n",
    "ret, img_bin = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "#img = l25.loadImage(filename, 0)\n",
    "#thresh = l32.peakPick(img)\n",
    "#img_bin = abs(l32.threshold(img, thresh) - 1)  # Given this set of data we need to flip the values\n",
    "#img_bin = cv2.erode(img_bin, kernel, iterations=2)\n",
    "moment = cv2.moments(img_bin)\n",
    "img_props = cv2.HuMoments(moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_props = img_props.reshape((1, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printImgGray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_props.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = img_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.append(samples, img_props, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images_train/obj0_0.jpg', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, img2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printImgGray(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l42 = [10, 3, 4]\n",
    "l42a = np.array([l42], dtype=np.float32)\n",
    "print(l42a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l42a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moment = cv2.moments(img)\n",
    "hu_moment = cv2.HuMoments(moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_moment.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openCV",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
